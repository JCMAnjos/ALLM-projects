{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:415\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/torch/serialization.py:1033\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1029\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1030\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1033\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39;49mload(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1034\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFalcon/falcon-7b/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m rrmodel \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model, \n\u001b[1;32m      4\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mbfloat16,\n\u001b[1;32m      5\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m     offload_folder\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moffload\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,)\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m     12\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOnce upon a time\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:466\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m     model_class \u001b[39m=\u001b[39m get_class_from_dynamic_module(\n\u001b[1;32m    463\u001b[0m         pretrained_model_name_or_path, module_file \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m, class_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    464\u001b[0m     )\n\u001b[1;32m    465\u001b[0m     model_class\u001b[39m.\u001b[39mregister_for_auto_class(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 466\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    467\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    468\u001b[0m     )\n\u001b[1;32m    469\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    470\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:2648\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2638\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2641\u001b[0m     (\n\u001b[1;32m   2642\u001b[0m         model,\n\u001b[1;32m   2643\u001b[0m         missing_keys,\n\u001b[1;32m   2644\u001b[0m         unexpected_keys,\n\u001b[1;32m   2645\u001b[0m         mismatched_keys,\n\u001b[1;32m   2646\u001b[0m         offload_index,\n\u001b[1;32m   2647\u001b[0m         error_msgs,\n\u001b[0;32m-> 2648\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2649\u001b[0m         model,\n\u001b[1;32m   2650\u001b[0m         state_dict,\n\u001b[1;32m   2651\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2652\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2653\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2654\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2655\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2656\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2657\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2658\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2659\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2660\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2661\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2662\u001b[0m         load_in_8bit\u001b[39m=\u001b[39;49mload_in_8bit,\n\u001b[1;32m   2663\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   2664\u001b[0m     )\n\u001b[1;32m   2666\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n\u001b[1;32m   2668\u001b[0m \u001b[39m# make sure token embedding weights are still tied if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:2957\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, load_in_8bit, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[39mif\u001b[39;00m shard_file \u001b[39min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   2956\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 2957\u001b[0m state_dict \u001b[39m=\u001b[39m load_state_dict(shard_file)\n\u001b[1;32m   2959\u001b[0m \u001b[39m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   2960\u001b[0m \u001b[39m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   2962\u001b[0m     state_dict,\n\u001b[1;32m   2963\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2967\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   2968\u001b[0m )\n",
      "File \u001b[0;32m~/Área de Trabalho/Aplicacoes LLM/Projeto/FalconVirtualEnv/lib/python3.10/site-packages/transformers/modeling_utils.py:420\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(checkpoint_file) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    419\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mread(\u001b[39m7\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 420\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    421\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou seem to have cloned a repository without having git-lfs installed. Please install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgit-lfs and run `git lfs install` followed by `git lfs pull` in the folder \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou cloned.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to locate the file \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_file\u001b[39m}\u001b[39;00m\u001b[39m which is necessary to load this pretrained \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel. Make sure you have saved the model properly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned."
     ]
    }
   ],
   "source": [
    "model = \"Falcon/falcon-7b/\"\n",
    "\n",
    "rrmodel = AutoModelForCausalLM.from_pretrained(model, \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    offload_folder=\"offload\",\n",
    "    device_map=\"auto\",)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "\n",
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = torch.ones(input_ids.shape)\n",
    "\n",
    "output = rrmodel.generate(input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            max_length=200,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FalconVirtualEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
