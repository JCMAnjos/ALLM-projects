{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBd_fso7qFPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691510ab-0819-401e-9bbc-20013ad33da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "# Import Chat completion template and set-up variables\n",
        "!pip install openai\n",
        "import openai\n",
        "import urllib.parse\n",
        "\n",
        "openai.api_key = \"EMPTY\" # Key is ignored and does not matter\n",
        "openai.api_base = \"http://zanino.millennium.berkeley.edu:8000/v1\"\n",
        "# Alternate mirrors\n",
        "# openai.api_base = \"http://34.132.127.197:8000/v1\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Gorilla server\n",
        "def get_gorilla_response(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v1\"):\n",
        "  try:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "  except Exception as e:\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def get_gorilla_response_Teste(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v1\"):\n",
        "  try:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return completion\n",
        "  except Exception as e:\n",
        "    return \"\"\n",
        "\n",
        "def get_gorilla_response_Sysem_Teste(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v1\"):\n",
        "  try:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[{\"role\": \"system\", \"content\": prompt}]\n",
        "    )\n",
        "    return completion\n",
        "  except Exception as e:\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "erCv6xPMxYBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Act like a store seller. The store sells 5 fuscas and 5 mustangs\"\n",
        "print(get_gorilla_response_Sysem_Teste(prompt, model=\"gorilla-mpt-7b-hf-v0\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcK0u3NXxYv_",
        "outputId": "ee74b0ab-acae-4402-ab83-30c7bcace609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-3iXzWQDViq6bvPFRoFQSvq\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1688930156,\n",
            "  \"model\": \"gorilla-mpt-7b-hf-v0\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"<<<domain>>>: Natural Language Processing Text2Text Generation\\\\n<<<api_call>>>: T5ForConditionalGeneration.from_pretrained('google/fusbot-t5-base')\\\\n<<<api_provider>>>: Hugging Face Transformers\\\\n<<<explanation>>>: 1. Import the T5ForConditionalGeneration class from the transformers package provided by Hugging Face.\\\\n2. Load the pre-trained Fusbot T5 model using the from_pretrained method. The model is trained for generating text based on a given input.\\\\n3. Define the input prompt as the description of the store's sale: \\\\\\\"5 fuscas and 5 mustangs for sale.\\\\\\\"\\\\n4. Use the T5 model to generate the advertisement text by passing the input prompt to the model's generate method.\\\\n5. Print the generated advertisement text.\\\\n<<<code>>>: from transformers import T5ForConditionalGeneration\\\\nmodel = T5ForConditionalGeneration.from_pretrained('google/fusbot-t5-base')\\\\ninput_prompt = \\\\\\\"5 fuscas and 5 mustangs for sale.\\\\\\\"\\\\nadvertisement = model.generate(input_prompt)\\\\nprint(advertisement[0]['generated_text'])\\\" \"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 31,\n",
            "    \"total_tokens\": 301,\n",
            "    \"completion_tokens\": 270\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Act like a store seller\"\n",
        "print(get_gorilla_response_Teste(prompt, model=\"gorilla-mpt-7b-hf-v0\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvtx6ZQOycML",
        "outputId": "5f488347-259e-45a4-e1d4-cdcfc9469521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-39ieHsMWTjMvFG4eSmm6oZ\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1688930182,\n",
            "  \"model\": \"gorilla-mpt-7b-hf-v0\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \" <<<domain>>>: Natural Language Processing Text Generation\\\\n<<<api_call>>>: pipeline('text-generation', model='bigscience/bloomz-560m')\\\\n<<<api_provider>>>: Hugging Face Transformers\\\\n<<<explanation>>>: 1. Import the 'pipeline' function from the transformers library provided by Hugging Face.\\\\n2. Use the 'pipeline' function to create a text generation model by specifying 'text-generation' as the task and 'bigscience/bloomz-560m' as the model to be used.\\\\n3. This model, called 'gpt2' for consistency with the Hugging Face model naming convention, is a powerful language model capable of generating coherent text based on a given input.\\\\n4. As a store seller, you can use this model to generate engaging and persuasive promotional text for various products or services.\\\\n<<<code>>>: from transformers import pipeline\\\\ngenerator = pipeline('text-generation', model='bigscience/bloomz-560m')\\\\npromo_text = generator(\\\\\\\"Our new smartwatch is perfect for those active lifestyles. With a sleek design and impressive battery life, it's sure to please any customer.\\\\\\\")\\\\n\\\" \"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 117,\n",
            "    \"total_tokens\": 382,\n",
            "    \"completion_tokens\": 265\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NÃO CNSEGUI UTILIZAR O GORILLA PARA SIMULAR UM CHATBOT. ELE APENAS É CAPAZ DE RETORNAR UMA CHAMADA DE API!"
      ],
      "metadata": {
        "id": "PNeCy_Z254Wc"
      }
    }
  ]
}